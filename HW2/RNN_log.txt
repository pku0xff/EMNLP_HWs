Epoch number: 0.
Iteration number: 500. Loss: 1.162528395652771.
Iteration number: 1000. Loss: 1.0624333620071411.
Iteration number: 1500. Loss: 0.9628884196281433.
Iteration number: 2000. Loss: 3.656533718109131.
Iteration number: 2500. Loss: 0.1564209759235382.
Iteration number: 3000. Loss: 1.1904325485229492.
Epoch loss: 1.1982090552961688.
Eval: acc 0.9357964869775893, precision 0.9230698225398266, recall 0.05381163506204706, F1 0.10168441998731016.

Epoch number: 1.
Iteration number: 500. Loss: 0.9400935769081116.
Iteration number: 1000. Loss: 0.9465913772583008.
Iteration number: 1500. Loss: 0.7613169550895691.
Iteration number: 2000. Loss: 3.5964720249176025.
Iteration number: 2500. Loss: 0.17334353923797607.
Iteration number: 3000. Loss: 1.2150484323501587.
Epoch loss: 1.064630598636703.
Eval: acc 0.9385221078134464, precision 0.9545411157222012, recall 0.09417036135858235, F1 0.17141208646834902.

Epoch number: 2.
Iteration number: 500. Loss: 0.7387610077857971.
Iteration number: 1000. Loss: 0.8888314366340637.
Iteration number: 1500. Loss: 0.5768287181854248.
Iteration number: 2000. Loss: 3.5839409828186035.
Iteration number: 2500. Loss: 0.15983854234218597.
Iteration number: 3000. Loss: 1.111249566078186.
Epoch loss: 0.9752019722143708.
Eval: acc 0.9427619624470018, precision 0.9473659279844, recall 0.16143490518614118, F1 0.27583698052325567.

Epoch number: 3.
Iteration number: 500. Loss: 0.591046929359436.
Iteration number: 1000. Loss: 0.8193447589874268.
Iteration number: 1500. Loss: 0.32133427262306213.
Iteration number: 2000. Loss: 3.43379807472229.
Iteration number: 2500. Loss: 0.15019258856773376.
Iteration number: 3000. Loss: 1.018755316734314.
Epoch loss: 0.9007512602037253.
Eval: acc 0.9448818897637795, precision 0.8867907796400384, recall 0.21076223732635097, F1 0.34054843537689033.

Epoch number: 4.
Iteration number: 500. Loss: 0.4350847601890564.
Iteration number: 1000. Loss: 0.7566908597946167.
Iteration number: 1500. Loss: 0.21333818137645721.
Iteration number: 2000. Loss: 3.1202032566070557.
Iteration number: 2500. Loss: 0.1381980925798416.
Iteration number: 3000. Loss: 0.8808821439743042.
Epoch loss: 0.837504028969628.
Eval: acc 0.9494245911568746, precision 0.9242410238772365, recall 0.27354247823207256, F1 0.4221097956686897.

Epoch number: 5.
Iteration number: 500. Loss: 0.29264745116233826.
Iteration number: 1000. Loss: 0.7198530435562134.
Iteration number: 1500. Loss: 0.1725466102361679.
Iteration number: 2000. Loss: 2.868156909942627.
Iteration number: 2500. Loss: 0.10765687376260757.
Iteration number: 3000. Loss: 0.7327715754508972.
Epoch loss: 0.7839505156550468.
Eval: acc 0.950030284675954, precision 0.9142844081651311, recall 0.2869953869975843, F1 0.4368234068921896.

Epoch number: 6.
Iteration number: 500. Loss: 0.15735724568367004.
Iteration number: 1000. Loss: 0.7216867208480835.
Iteration number: 1500. Loss: 0.15319880843162537.
Iteration number: 2000. Loss: 2.740330219268799.
Iteration number: 2500. Loss: 0.0974583551287651.
Iteration number: 3000. Loss: 0.5838924050331116.
Epoch loss: 0.7443085774326319.
Eval: acc 0.9506359781950333, precision 0.8749989062513671, recall 0.3139012045286078, F1 0.462007039601269.

Epoch number: 7.
Iteration number: 500. Loss: 0.07785123586654663.
Iteration number: 1000. Loss: 0.7347658276557922.
Iteration number: 1500. Loss: 0.13238029181957245.
Iteration number: 2000. Loss: 2.633488893508911.
Iteration number: 2500. Loss: 0.08608540892601013.
Iteration number: 3000. Loss: 0.45536237955093384.
Epoch loss: 0.7122917221053093.
Eval: acc 0.9542701393095094, precision 0.8829777840661871, recall 0.37219714251249214, F1 0.5236172589333532.

Epoch number: 8.
Iteration number: 500. Loss: 0.047005753964185715.
Iteration number: 1000. Loss: 0.7464299201965332.
Iteration number: 1500. Loss: 0.1079222559928894.
Iteration number: 2000. Loss: 2.628941297531128.
Iteration number: 2500. Loss: 0.06861214339733124.
Iteration number: 3000. Loss: 0.3644507825374603.
Epoch loss: 0.6857215511010054.
Eval: acc 0.955481526347668, precision 0.8877541961691876, recall 0.39013435419984116, F1 0.5420133222800093.

Epoch number: 9.
Iteration number: 500. Loss: 0.032106321305036545.
Iteration number: 1000. Loss: 0.755432665348053.
Iteration number: 1500. Loss: 0.08409815281629562.
Iteration number: 2000. Loss: 2.6398143768310547.
Iteration number: 2500. Loss: 0.056987740099430084.
Iteration number: 3000. Loss: 0.30739840865135193.
Epoch loss: 0.6645657969239934.
Eval: acc 0.9576014536644458, precision 0.8952372426311974, recall 0.42152447465270193, F1 0.5731268567332705.

Epoch number: 10.
Iteration number: 500. Loss: 0.025109577924013138.
Iteration number: 1000. Loss: 0.7726112008094788.
Iteration number: 1500. Loss: 0.06623948365449905.
Iteration number: 2000. Loss: 2.6459715366363525.
Iteration number: 2500. Loss: 0.04824216291308403.
Iteration number: 3000. Loss: 0.25614485144615173.
Epoch loss: 0.6462564883557124.
Eval: acc 0.9572986069049061, precision 0.8867916162343242, recall 0.42152447465270193, F1 0.5713845507757054.

Epoch number: 11.
Iteration number: 500. Loss: 0.023986125364899635.
Iteration number: 1000. Loss: 0.7966248989105225.
Iteration number: 1500. Loss: 0.05585525557398796.
Iteration number: 2000. Loss: 2.6235837936401367.
Iteration number: 2500. Loss: 0.042047955095767975.
Iteration number: 3000. Loss: 0.20859360694885254.
Epoch loss: 0.6299416915628537.
Eval: acc 0.9582071471835252, precision 0.8899074404518895, recall 0.4349773834182137, F1 0.5842928959767641.

Epoch number: 12.
Iteration number: 500. Loss: 0.02279829978942871.
Iteration number: 1000. Loss: 0.8174046874046326.
Iteration number: 1500. Loss: 0.04788484051823616.
Iteration number: 2000. Loss: 2.5818276405334473.
Iteration number: 2500. Loss: 0.03921867161989212.
Iteration number: 3000. Loss: 0.20147234201431274.
Epoch loss: 0.615328917304822.
Eval: acc 0.9582071471835252, precision 0.8828820874936149, recall 0.43946168634005095, F1 0.5867816215499371.

Epoch number: 13.
Iteration number: 500. Loss: 0.01907804049551487.
Iteration number: 1000. Loss: 0.8317731618881226.
Iteration number: 1500. Loss: 0.04530053585767746.
Iteration number: 2000. Loss: 2.533479690551758.
Iteration number: 2500. Loss: 0.036858074367046356.
Iteration number: 3000. Loss: 0.19515396654605865.
Epoch loss: 0.6037400410489605.
Eval: acc 0.9582071471835252, precision 0.8971954231818474, recall 0.43049308049637647, F1 0.5817740106392789.

Epoch number: 14.
Iteration number: 500. Loss: 0.017913224175572395.
Iteration number: 1000. Loss: 0.8446733355522156.
Iteration number: 1500. Loss: 0.04470869153738022.
Iteration number: 2000. Loss: 2.5058882236480713.
Iteration number: 2500. Loss: 0.03271111100912094.
Iteration number: 3000. Loss: 0.18260115385055542.
Epoch loss: 0.593506843683612.
Eval: acc 0.9582071471835252, precision 0.8971954231818474, recall 0.43049308049637647, F1 0.5817740106392789.

Epoch number: 15.
Iteration number: 500. Loss: 0.017400899901986122.
Iteration number: 1000. Loss: 0.8543188571929932.
Iteration number: 1500. Loss: 0.0448124036192894.
Iteration number: 2000. Loss: 2.50801682472229.
Iteration number: 2500. Loss: 0.02741791307926178.
Iteration number: 3000. Loss: 0.1665508896112442.
Epoch loss: 0.583911765973857.
Eval: acc 0.9585099939430648, precision 0.8909082809924718, recall 0.43946168634005095, F1 0.588543995959911.

Training cost 449.331848859787 seconds.

Test: acc 0.9645894809928832, precision 0.8385540148062616, recall 0.5050797525283378, F1 0.6303877517644119.
